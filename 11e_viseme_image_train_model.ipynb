{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0042ebe0",
   "metadata": {},
   "source": [
    "# Train image model\n",
    "\n",
    "> Train a convnet using fastai (on colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6738f",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html\n",
    "\n",
    "https://dev.to/tkeyo/export-fastai-resnet-models-to-onnx-2gj7\n",
    "\n",
    "## Running this notebook in colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pete88b/expoco/blob/main/11e_viseme_image_train_model.ipynb)\n",
    "\n",
    "### Change runtime type to use GPU\n",
    "\n",
    "### Run the following cell, then restart the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5196d33f-d07f-45da-af21-fdd22aad2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "! [ -e /content ] && pip install -Uqq fastai # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49d61d",
   "metadata": {},
   "source": [
    "## After runtime restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19042066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, json, torchvision\n",
    "from fastai.vision.all import *\n",
    "from zipfile import ZipFile\n",
    "path = Path('/content/data')\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c8de0",
   "metadata": {},
   "source": [
    "## Copy your `data.zip` and `metadata.json` to your google drive\n",
    "\n",
    "Update the path in the following cell to the point to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = Path('/content/drive/MyDrive/Colab Notebooks/datasets/expoco/viseme_image_dataset_20220202')\n",
    "zip_file_path = source_path/'data.zip'\n",
    "assert zip_file_path.is_file(), f'{zip_file_path} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903bf07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ZipFile(zip_file_path)\n",
    "z.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727863a",
   "metadata": {},
   "source": [
    "## Onnx helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62288a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def now():\n",
    "    \"Return a timestamp string that can be used in file or directory names\"\n",
    "    return datetime.utcnow().strftime('%Y%m%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c633f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_export():\n",
    "    torch_model = learn.model.cpu().eval() # by the time this fn is called, learn will exist\n",
    "    model = nn.Sequential(\n",
    "        torchvision.transforms.Normalize(**stats),\n",
    "        torch_model,\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    batch_size = 2\n",
    "    # Input to the model\n",
    "    x = torch.randn(batch_size, 3, 256, 256, requires_grad=True)\n",
    "    torch_out = model(x)\n",
    "\n",
    "    model_id = now()\n",
    "    output_path = path/f'model_{model_id}'\n",
    "    print('output_path', output_path)\n",
    "    output_path.mkdir()\n",
    "    file_name = output_path/'resnet_3_256_256.onnx'\n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(model,                     # model being run\n",
    "                      x,                         # model input (or a tuple for multiple inputs)\n",
    "                      file_name,                 # where to save the model (can be a file or file-like object)\n",
    "                      export_params=True,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input'],   # the model's input names\n",
    "                      output_names = ['output'], # the model's output names\n",
    "                      dynamic_axes = {'input': {0: 'batch_size'},    # variable length axes\n",
    "                                      'output': {0: 'batch_size'}})\n",
    "    print('Exported to', file_name)\n",
    "    return file_name, x, torch_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148ff15",
   "metadata": {},
   "source": [
    "## Read `stats` from `metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61764063",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(source_path/'metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "stats = metadata['stats']\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f1a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_bgr_to_rgb(stats):\n",
    "    \"Convert stats for cv2 style to fastai/pytorch style\"\n",
    "    def _permute(a): return [a[2], a[1], a[0]]\n",
    "    return {k:_permute(v) for k,v in stats.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4a469",
   "metadata": {},
   "source": [
    "## Train a resnet with fastai\n",
    "\n",
    "### TODO: Create a separate set of validation (and test) data\n",
    "\n",
    "random sample of images for validation is too easy - validation images will all have an image in the training data that is very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_block = DataBlock(blocks=(ImageBlock(cls=PILImage), CategoryBlock),\n",
    "                       get_items=get_image_files,\n",
    "                       splitter=RandomSplitter(),\n",
    "                       get_y=parent_label,\n",
    "                       batch_tfms=[Normalize.from_stats(**stats_bgr_to_rgb(stats))] + aug_transforms())\n",
    "dls=data_block.dataloaders(path, bs=256)\n",
    "dls.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=8,figsize=(14,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0191aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=cnn_learner(dls, resnet18, metrics=[accuracy], wd=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()\n",
    "base_lr = 1e-3 # <- this lr should be fine but you might want to change as per lr_find recommendation\n",
    "learn.fit_one_cycle(10, base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_unfreeze_onnx_path, x, torch_out = onnx_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(base_lr/100, base_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85031ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path, x, torch_out = onnx_export() # this is probably the one we want to keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc2d14",
   "metadata": {},
   "source": [
    "## Download resnet_3_256_256.onnx to your machine ...\n",
    "\n",
    "... before the colab session times out\n",
    "\n",
    "I also download the notebook as a record of how the model was trained - not the most robust experiment tracking (o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.print_classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e06396",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66829c46",
   "metadata": {},
   "source": [
    "## Check the onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8449f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx, onnxruntime\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d86d3c",
   "metadata": {},
   "source": [
    "In the cell below; `x` and `torch_out` were retured by a previous call to `onnx_export()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(str(onnx_path))\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5db6941",
   "metadata": {},
   "source": [
    "## Terminate your colab session (o: just not before your model download has finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
