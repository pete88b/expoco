{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gui.main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042ebe0",
   "metadata": {},
   "source": [
    "# ExPoCo GUI\n",
    "\n",
    "> The main expoco app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa901c",
   "metadata": {},
   "source": [
    "TODO: abstract out win32 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7c30aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from expoco.core import *\n",
    "from expoco.ml.data import *\n",
    "from expoco.ml.model import *\n",
    "from expoco.gui.capture_command import *\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2, time, math, json\n",
    "import win32api, win32con\n",
    "from PIL import Image\n",
    "\n",
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba33cd1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2374f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# model_path = Path('data/viseme_dataset_20211116_113131/processed_20211116_131807/model_20211116_132150')\n",
    "# relative_landmark_id=FaceLandmarks.tip_of_nose\n",
    "model_path = Path('data/viseme_dataset_20211116_113131/processed_20211117_200746/model_20211117_201151')\n",
    "relative_landmark_id=None\n",
    "model = load_tabular_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbdacc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "with open(model_path.parent/'metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "cont_names = metadata['cont_names']\n",
    "y_name = metadata['y_name']\n",
    "stats = np.load(model_path.parent/'stats.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a3890",
   "metadata": {},
   "source": [
    "# other ... todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a8b08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen_width, screen_height 1280 720\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "screen_width, screen_height = win32api.GetSystemMetrics(0), win32api.GetSystemMetrics(1)\n",
    "print('screen_width, screen_height', screen_width, screen_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e0dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class FacePoint:\n",
    "    x: int\n",
    "    y: int\n",
    "    def __call__(self): return self.x, self.y\n",
    "    def __repr__(self): return f'({self.x},{self.y})'\n",
    "    \n",
    "@dataclass\n",
    "class FacePoints:\n",
    "    tip_of_nose: FacePoint\n",
    "    up: FacePoint\n",
    "    down: FacePoint\n",
    "    left: FacePoint\n",
    "    right: FacePoint\n",
    "    face_point_ids = [1, 5, 2, 218, 438]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9d8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FacePointHelper:\n",
    "    def __init__(self, image_width, image_height, screen_width, screen_height): # TODO: remove screen_width, screen_height\n",
    "        self.image_width, self.image_height = image_width, image_height\n",
    "        self.screen_width, self.screen_height = screen_width, screen_height\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "        \n",
    "    def process(self, image):\n",
    "        self.results = self.face_mesh.process(image) # cv2.cvtColor(image, cv2.COLOR_BGR2RGB) already done\n",
    "        return self.results\n",
    "        \n",
    "    def face_points(self, pixel_coordinates=True):\n",
    "        fn = self._landmark_to_pixel_coordinates if pixel_coordinates else self._landmark_to_x_y\n",
    "        return FacePoints(\n",
    "            *[FacePoint(*fn(i)) for i in FacePoints.face_point_ids])\n",
    "        \n",
    "    def face_orientation(self, calibration): # TODO: better name, this is face angle / where it's pointing to / face|facial orientation\n",
    "        points = self.face_points(False)\n",
    "        l = points.tip_of_nose.x - points.left.x\n",
    "        r = points.right.x - points.tip_of_nose.x\n",
    "        u = points.tip_of_nose.y - points.up.y\n",
    "        d = points.down.y - points.tip_of_nose.y\n",
    "        pan = (l - r) - calibration[0] \n",
    "        tilt = (u - d) - calibration[1] # - 0.018 # TODO: calibrate\n",
    "        return pan, tilt, 0.0\n",
    "\n",
    "    def _landmark(self, i):\n",
    "        return self.results.multi_face_landmarks[0].landmark[i] # [0] is OK as we're running with max_num_faces=1\n",
    "        \n",
    "    def _is_valid_normalized_value(self, value):\n",
    "        return (value > 0 or math.isclose(0, value)) and (value < 1 or math.isclose(1, value))\n",
    "    \n",
    "    def _normalized_x_to_pixel(self, value):\n",
    "        return math.floor(value * self.image_width)\n",
    "    \n",
    "    def _normalized_y_to_pixel(self, value):\n",
    "        return math.floor(value * self.image_height)\n",
    "    \n",
    "    def _landmark_to_x_y(self, landmark):\n",
    "        if isinstance(landmark, int):\n",
    "            landmark = self._landmark(landmark)\n",
    "        if not (self._is_valid_normalized_value(landmark.x) and self._is_valid_normalized_value(landmark.y)):\n",
    "            print(f'WARNING: {landmark.x} or {landmark.y} is not a valid normalized value')\n",
    "        return landmark.x, landmark.y\n",
    "    \n",
    "    def _landmark_to_pixel_coordinates(self, landmark):\n",
    "        x, y = self._landmark_to_x_y(landmark)\n",
    "        return self._normalized_x_to_pixel(x), self._normalized_y_to_pixel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14973358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calibrate():\n",
    "    win32api.SetCursorPos([screen_width//2, screen_height//2])\n",
    "    time.sleep(.5)\n",
    "    return face_point_helper.face_orientation([0.0,0.0,0.0])\n",
    "\n",
    "calibration = (0.0, 0.02087956666946411, 0.0)\n",
    "\n",
    "def _r(l): return [round(i, 5) for i in l]\n",
    "\n",
    "def move(yaw, pitch):\n",
    "    pointer_x_px, pointer_y_px = list(win32api.GetCursorPos())\n",
    "    pointer_x_px -= screen_width//2\n",
    "    pointer_x_px /= 6.5e4 # 4.5e4 # was 5.5e4 # TODO: calibrate/pref\n",
    "    pointer_speed = 250 # TODO: user pref\n",
    "    x_move = math.floor(((yaw - pointer_x_px) * pointer_speed)**3) \n",
    "    pointer_y_px -= screen_height//2\n",
    "    pointer_y_px /= 6.5e4 # 4.5e4 # was 5.5e4 # TODO: calibrate\n",
    "    y_move = math.floor(((pitch - pointer_y_px) * pointer_speed)**3) \n",
    "    x, y = win32api.GetCursorPos()\n",
    "    win32api.SetCursorPos([x + x_move, y + y_move])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d174604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StopExpocoException(Exception):\n",
    "    pass\n",
    "def stop_expoco():\n",
    "    raise StopExpocoException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51b67b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "Command = namedtuple('Command', ['key', 'label', 'fn'])\n",
    "commands = [\n",
    "    Command('q', 'Quit', stop_expoco),\n",
    "    Command('l', 'Left click', lambda: pointer_left_click(*get_pointer_position())),\n",
    "    Command('r', 'Right click', lambda: pointer_right_click(*get_pointer_position())),\n",
    "    Command('semicolon', 'Enter / Return', lambda: win32api.keybd_event(win32con.VK_RETURN, 0)),\n",
    "    Command('e', 'End', lambda: win32api.keybd_event(win32con.VK_END, 0)),\n",
    "    Command('h', 'Home', lambda: win32api.keybd_event(win32con.VK_HOME, 0)),\n",
    "    Command('d', 'Delete', lambda: win32api.keybd_event(win32con.VK_DELETE, 0)),\n",
    "    Command('b', 'Backspace', lambda: win32api.keybd_event(win32con.VK_BACK, 0)),\n",
    "    Command('as', 'Test seq', lambda: print('\"as\" sequence hit')),\n",
    "]\n",
    "command_map = {c.key: c for c in commands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11070263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_main():\n",
    "    try: video_capture.release() # TODO: del\n",
    "    except: pass\n",
    "    try:\n",
    "        video_capture = cv2.VideoCapture(0) \n",
    "        face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "        for vk in [win32con.VK_ESCAPE, ord('C')]: win32api.GetAsyncKeyState(vk)\n",
    "        retval, image = video_capture.read()\n",
    "        face_point_helper = FacePointHelper(*image.shape[:2], screen_width, screen_height)\n",
    "        hist_len = 15\n",
    "        x_hist, y_hist, hist_idx = np.zeros(hist_len), np.zeros(hist_len), 0\n",
    "        while True:\n",
    "            retval, image = video_capture.read()\n",
    "            image = cv2.flip(image, 1)\n",
    "            results = face_point_helper.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            face_orientation = face_point_helper.face_orientation(calibration)\n",
    "            move(face_orientation[0], face_orientation[1])\n",
    "        #     if win32api.GetAsyncKeyState(ord('C')):\n",
    "        #         calibration = calibrate()\n",
    "        #         print('calibration', calibration)\n",
    "\n",
    "            #viseme start\n",
    "            # TODO: read metadata.json and build dynamically\n",
    "            data = inference_data_from_landmarks(\n",
    "                    landmarks=results.multi_face_landmarks[0].landmark, \n",
    "                    landmark_ids=FaceLandmarks.pointer + FaceLandmarks.mouth,\n",
    "                    relative_landmark_id=relative_landmark_id, \n",
    "                    coords=['x', 'y'], \n",
    "                    stats=stats)\n",
    "            output = model(data)\n",
    "            class_id = np.argmax(output)\n",
    "            if class_id == 1:\n",
    "                keys_pressed = capture_key_press([f\"{c.key}: {c.label}\" for c in commands], not pointer_in_left_half_of_screen())\n",
    "                print('keys_pressed', keys_pressed)\n",
    "                run_command(command_map, keys_pressed)\n",
    "        #     class_label = viseme_config.get_class_label(class_id)\n",
    "        #     print('class_id', class_id, output)\n",
    "            #viseme end\n",
    "\n",
    "    #         if win32api.GetAsyncKeyState(win32con.VK_ESCAPE): \n",
    "    #             break\n",
    "            time.sleep(.05)\n",
    "    except StopExpocoException:\n",
    "        video_capture.release()\n",
    "    finally:\n",
    "        video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "053356ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys_pressed ['q']\n"
     ]
    }
   ],
   "source": [
    "run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ee86d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 05a_ml_data.ipynb.\n",
      "Converted 05b_ml_model.ipynb.\n",
      "Converted 10a_mediapipe_face_mesh_identify_landmarks.ipynb.\n",
      "Converted 10b_mediapipe_face_mesh_capture_session.ipynb.\n",
      "Converted 10c_mediapipe_face_mesh_train_model.ipynb.\n",
      "Converted 10d_test_np_model.ipynb.\n",
      "Converted 20a_gui_capture_command.ipynb.\n",
      "Converted 20a_gui_main.ipynb.\n",
      "Converted 70_cli.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted project_lifecycle.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
