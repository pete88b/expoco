{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine 0:no expression and 4:random into a single 0:ignore class\n",
    "\n",
    "at inference time, we don't care about the difference\n",
    "\n",
    "the class imbalance might also be useful - as this will be our do nothing default - and we only want to take action when we're sure a command is being requested\n",
    "\n",
    "see what happens if we don't use nose landmarks for training - try with/without normalizing for nose\n",
    "\n",
    "different \n",
    "- Try bigger batch size - even if it means we need more epochs\n",
    "- model size/depth\n",
    "- Exaggerate 0 imbalance - how far do we have to go to not got any 0s misclassified (on test set)combine 0:no expression and 4:random into a single 0:ignore class\n",
    "\n",
    "at inference time, we don't care about the difference\n",
    "\n",
    "the class imbalance might also be useful - as this will be our do nothing default - and we only want to take action when we're sure a command is being requested\n",
    "\n",
    "see what happens if we don't use nose landmarks for training - try with/without normalizing for nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# run this, then restart the runtime\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24600/227321718.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtabular\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai.tabular.all import *\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = '20211014143136'\n",
    "path = Path('/content/drive/MyDrive/Colab Notebooks/datasets')\n",
    "df = pd.read_csv(path/f'data_{dataset_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all x and y values relative to tip of nose\n",
    "for i in range(468):\n",
    "    df[f'{i}x']=df[f'{i}x']-df['1x']\n",
    "    df[f'{i}y']=df[f'{i}y']-df['1y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate stats for normalization\n",
    "stats = {}\n",
    "for i in range(468):\n",
    "    for coord in ['x','y','z']: \n",
    "        col=f'{i}{coord}'\n",
    "        stats[col]={}\n",
    "        stats[col]['mean']=df[col].mean()\n",
    "        stats[col]['std']=df[col].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these stats so we can use them at inference time\n",
    "import json\n",
    "with open(path/f'stats_data_{dataset_id}.json', 'w') as f:\n",
    "    json.dump(stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "for i in range(468):\n",
    "    if i == 1: continue # it's all zeros\n",
    "    for coord in ['x','y','z']:\n",
    "        col=f'{i}{coord}'\n",
    "        df[col]=df[col]-stats[col]['mean']\n",
    "        df[col]=df[col]/stats[col]['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expression_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine 0:no expression and 4:random into a single 0:ignore class\n",
    "df.loc[df['expression_id']==4, 'expression_id']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_point_ids = [5, 2, 218, 438] # up,down,left,right - no point having 1 tip_of_nose as it's always 0\n",
    "mouth_landmarks = [0, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 39, 40, 41, 42, 43, 57, 61, 62, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 106, 146, 164, 165, 167, 178, 179, 180, 181, 182, 183, 184, 185, 186, 191, 204, 267, 268, 269, 270, 271, 272, 273, 287, 291, 292, 302, 303, 304, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 335, 375, 391, 393, 402, 403, 404, 405, 406, 407, 408, 409, 410, 415, 424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = []\n",
    "for i in face_point_ids+mouth_landmarks:\n",
    "# for i in range(468):\n",
    "    cont_names.append(f'{i}x')\n",
    "    cont_names.append(f'{i}y')\n",
    "cat_names = []\n",
    "procs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(face_point_ids+mouth_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = RandomSplitter(valid_pct=0.2)(range_of(df))\n",
    "# to = TabularPandas(df, procs=procs,\n",
    "#                    cat_names = cat_names,\n",
    "#                    cont_names = cont_names,\n",
    "#                    y_names='expression_id',\n",
    "#                    splits=splits)\n",
    "# dls = to.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_df(df, path, procs=procs, cat_names=cat_names, cont_names=cont_names, \n",
    "                                 y_names=\"expression_id\", y_block=CategoryBlock,\n",
    "                                 valid_idx=list(range(0, len(df), 10)), bs=64)\n",
    "learn = tabular_learner(dls, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=accuracy)\n",
    "learn.fit_one_cycle(25, 8e-4, wd=1e-2) # 25, 8e-4 -> 97.4 + wd=1e-2 -> 97.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id_to_label = {\n",
    "        0: \"No expression\",\n",
    "        1: \"oo\",\n",
    "        2: \"ee\",\n",
    "        3: \"ah\",\n",
    "        4: \"Random Talking\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros([5,5], dtype=int) # TODO: don't hard code\n",
    "output = np_model(df[cont_names].to_numpy())\n",
    "preds = np.argmax(output, axis=1)\n",
    "targets = df['expression_id'].to_numpy()\n",
    "for p,t in zip(preds, targets):\n",
    "    confusion_matrix[t][p]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix = np.array([[0,2,1],[1,2,0],[2,1,0]])\n",
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "ax.matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.8)\n",
    "# ax.xaxis.set_ticks_position('bottom') # must be after matshow\n",
    "for i in range(confusion_matrix.shape[0]):\n",
    "    for j in range(confusion_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusion_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "tick_marks = np.arange(5)\n",
    "# plt.xticks(tick_marks, self.data.y.classes, rotation=90)\n",
    "plt.xticks(tick_marks, class_id_to_label.values(), rotation=90)\n",
    "plt.yticks(tick_marks, class_id_to_label.values(), rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class NpModelHelper:\n",
    "    def __init__(self, path, model_id):\n",
    "        self.model_id, self.path = model_id, path/f'model_{model_id}.pkl'\n",
    "    def set_state(self, model):\n",
    "        self.state_dict, state_dict = {}, learn.model.state_dict()\n",
    "        for k in state_dict:\n",
    "            self.state_dict[k] = state_dict[k].detach().cpu().numpy()\n",
    "        return self\n",
    "    def save(self):\n",
    "        # can't set allow_pickle=False with np.savez https://github.com/numpy/numpy/issues/13983\n",
    "        # so we might as well pickle and keep the dict order\n",
    "        # TODO: don't need the dict order any more - go back to npz\n",
    "        with open(self.path, 'wb') as f:\n",
    "            pickle.dump(self.state_dict, f)\n",
    "        return self\n",
    "    def load(self):\n",
    "        with open(self.path, 'rb') as f:\n",
    "            self.state_dict = pickle.load(f)\n",
    "        return self\n",
    "    def get_state_dict(self, name_prefix):\n",
    "        if name_prefix is None or name_prefix == '': \n",
    "            return self.state_dict\n",
    "        return {k[len(name_prefix)+1:]:self.state_dict[k] \n",
    "                for k in self.state_dict \n",
    "                if k.startswith(name_prefix)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_helper = NpModelHelper(path, dataset_id)\n",
    "np_model_helper.set_state(learn.model).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_helper.get_state('bn_cont').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_helper = NpModelHelper(path, dataset_id).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model_helper = NpModelHelper(path, dataset_id).load()\n",
    "np_model = NpModel([\n",
    "                    NpBatchNorm1d(**np_model_helper.get_state_dict('bn_cont')),\n",
    "                    NpLinear(**np_model_helper.get_state_dict('layers.0.0')),\n",
    "                    NpReLU(),\n",
    "                    NpBatchNorm1d(**np_model_helper.get_state_dict('layers.0.2')),\n",
    "                    NpLinear(**np_model_helper.get_state_dict('layers.1.0')),\n",
    "                    NpReLU(),\n",
    "                    NpBatchNorm1d(**np_model_helper.get_state_dict('layers.1.2')),\n",
    "                    NpLinear(**np_model_helper.get_state_dict('layers.2.0'))\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_params_to_np(module, name):\n",
    "    t = getattr(module, name)\n",
    "    if t is not None:\n",
    "        t = t.detach().cpu().numpy()\n",
    "    return t\n",
    "\n",
    "def model_params_to_np(m):\n",
    "    # currently just for fastai TabularModel\n",
    "    result = {}\n",
    "    def _add(name_prefix, module, names):\n",
    "        for name in names:\n",
    "            result[f'{name_prefix}{name}'] = module_params_to_np(module, name)\n",
    "    _add('bn_cont#', m.bn_cont, ['weight','bias','running_mean','running_var']) # BatchNorm1d\n",
    "    _add('layers#0#0#', m.layers[0][0], ['weight','bias']) # Linear\n",
    "    _add('layers#0#2#', m.layers[0][2], ['weight','bias','running_mean','running_var'])\n",
    "    _add('layers#1#0#', m.layers[1][0], ['weight','bias'])\n",
    "    _add('layers#1#2#', m.layers[1][2], ['weight','bias','running_mean','running_var'])\n",
    "    _add('layers#2#0#', m.layers[2][0], ['weight','bias'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " np_params = model_params_to_np(learn.model)\n",
    " np.savez(path/'model_20211014143136.npz', **np_params) # TODO: save without pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpBatchNorm1d:\n",
    "    # https://github.com/pytorch/pytorch/blob/420b37f3c67950ed93cd8aa7a12e673fcfc5567b/aten/src/ATen/native/Normalization.cpp#L61-L126\n",
    "    def __init__(self, weight, bias, running_mean, running_var, num_batches_tracked=None):\n",
    "        self.weight, self.bias = weight, bias\n",
    "        self.running_mean, self.running_std = running_mean, np.sqrt(running_var + 1e-5)\n",
    "    def __call__(self, x):\n",
    "        x = x - self.running_mean\n",
    "        x = x / self.running_std\n",
    "        x = x * self.weight\n",
    "        x = x + self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpLinear:\n",
    "    def __init__(self, weight, bias=None):\n",
    "        self.weight, self.bias = weight.T, bias\n",
    "    def __call__(self, x):\n",
    "        x = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpReLU:\n",
    "    def __call__(self, x):\n",
    "        return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpModel:\n",
    "    def __init__(self, modules):\n",
    "        self.modules = modules\n",
    "    def __call__(self, x):\n",
    "        for module in self.modules:\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_file = np.load(path/'model_20211014143136.npz', allow_pickle=True)\n",
    "def _fix_none(arr):\n",
    "    return None if arr.shape == () else arr\n",
    "def np_params_from_npz(name_prefix, names):\n",
    "    return [_fix_none(npz_file[f'{name_prefix}{name}']) for name in names]\n",
    "np_model = NpModel([\n",
    "                    NpBatchNorm1d(*np_params_from_npz('bn_cont#', ['weight','bias','running_mean','running_var'])),\n",
    "                    NpLinear(*np_params_from_npz('layers#0#0#', ['weight','bias'])),\n",
    "                    NpReLU(),\n",
    "                    NpBatchNorm1d(*np_params_from_npz('layers#0#2#', ['weight','bias','running_mean','running_var'])),\n",
    "                    NpLinear(*np_params_from_npz('layers#1#0#', ['weight','bias'])),\n",
    "                    NpReLU(),\n",
    "                    NpBatchNorm1d(*np_params_from_npz('layers#1#2#', ['weight','bias','running_mean','running_var'])),\n",
    "                    NpLinear(*np_params_from_npz('layers#2#0#', ['weight','bias']))\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np_model(df[cont_names].to_numpy())\n",
    "preds = np.argmax(output, axis=1)\n",
    "targets = df['expression_id'].to_numpy()\n",
    "for i, (p,t) in enumerate(zip(preds,targets)):\n",
    "    if p!=t:\n",
    "        print(i,p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(df.iloc[9924])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "for i in [9922, 9923, 9924, 9925]:\n",
    "    _df = df.iloc[[i]]\n",
    "    output = np_model(_df[cont_names].to_numpy())\n",
    "    preds = np.argmax(output, axis=1)\n",
    "    targets = _df['expression_id'].to_numpy()\n",
    "    fastai_preds = learn.predict(df.iloc[i])\n",
    "    print(i,softmax(output),preds,targets,'\\n\\n')\n",
    "    print(fastai_preds,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This &darr; is the old way of saving model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpBatchNorm1d:\n",
    "    # https://github.com/pytorch/pytorch/blob/420b37f3c67950ed93cd8aa7a12e673fcfc5567b/aten/src/ATen/native/Normalization.cpp#L61-L126\n",
    "    def __init__(self, weight, bias, running_mean, running_var):\n",
    "        self.weight, self.bias = weight, bias\n",
    "        self.running_mean, self.running_var = running_mean, running_var\n",
    "        self.running_std = np.sqrt(running_var + 1e-5)\n",
    "    def __call__(self, x):\n",
    "        x = x - self.running_mean\n",
    "        x = x / self.running_std\n",
    "        x = x * self.weight\n",
    "        x = x + self.bias\n",
    "        return x\n",
    "    def params(self):\n",
    "        return dict(weight=self.weight, bias=self.bias, \n",
    "                    running_mean=self.running_mean, running_var=self.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpLinear:\n",
    "    def __init__(self, weight, bias):\n",
    "        self.weight, self.bias = weight.T, bias\n",
    "    def __call__(self, x):\n",
    "        x = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            x = x + self.bias\n",
    "        return x\n",
    "    def params(self):\n",
    "        return dict(weight=self.weight, bias=self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpReLU:\n",
    "    def __call__(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    def params(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpModel:\n",
    "    def __init__(self, modules):\n",
    "        self.modules = modules\n",
    "    def __call__(self, x):\n",
    "        for module in self.modules:\n",
    "            x = module(x)\n",
    "        return x\n",
    "    def params(self):\n",
    "        result = {}\n",
    "        for i, module in enumerate(self.modules):\n",
    "            name_prefix = f'{i}_{module.__class__.__name__}_'\n",
    "            module_params = module.params()\n",
    "            for k in module_params:\n",
    "                result[f'{name_prefix}{k}'] = module_params[k]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights_as_np(module, names):\n",
    "    result = []\n",
    "    for name in names:\n",
    "        t = getattr(module, name)\n",
    "        if t is not None:\n",
    "            t = t.detach().cpu().numpy()\n",
    "        result.append(t)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model\n",
    "np_model = NpModel([\n",
    "                    NpBatchNorm1d(*get_weights_as_np(m.bn_cont, ['weight','bias','running_mean','running_var'])),\n",
    "                    NpLinear(*get_weights_as_np(m.layers[0][0], ['weight','bias'])),\n",
    "                    NpReLU(),\n",
    "                    NpBatchNorm1d(*get_weights_as_np(m.layers[0][2], ['weight','bias','running_mean','running_var'])),\n",
    "                    NpLinear(*get_weights_as_np(m.layers[1][0], ['weight','bias'])),\n",
    "                    NpReLU(),\n",
    "                    NpBatchNorm1d(*get_weights_as_np(m.layers[1][2], ['weight','bias','running_mean','running_var'])),\n",
    "                    NpLinear(*get_weights_as_np(m.layers[2][0], ['weight','bias']))\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(path/'model_20211013102908.npz', **np_model.params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np_model(df[cont_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(output, axis=1)\n",
    "targets = df['expression_id'].to_numpy()\n",
    "for i, (p,t) in enumerate(zip(preds,targets)):\n",
    "    if p!=t:\n",
    "        print(i,p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expression_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.relu( l(x.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_l = NpLinear(*get_weights_as_np(l, ['weight','bias']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NpReLU()( np_l(x.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = m.layers[0][0]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones([1,212])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.bn_cont(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_bn = NpBatchNorm1d(*[getattr(m.bn_cont, n).detach().cpu().numpy() for n in ['weight','bias','running_mean','running_var']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_bn(x) # np_bn(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt( np_bn.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.bn_cont.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.bn_cont.running_mean.shape, m.bn_cont.running_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.bn_cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in m.bn_cont.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Linear(len(face_point_ids+mouth_landmarks)*2, 200, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 100, False),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 4, True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.m=nn.Sequential(\n",
    "            nn.Linear(len(face_point_ids+mouth_landmarks)*2, 200, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 100, False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 4, True)\n",
    "        )\n",
    "                \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x=self.m(x_cont)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=TabularLearner(dls, SimpleModel(),\n",
    "                     loss_func=CrossEntropyLossFlat(),\n",
    "                     wd=1e-3, wd_bn_bias=True)\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(15, 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
