{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp viseme_image.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042ebe0",
   "metadata": {},
   "source": [
    "# Viseme image dataset\n",
    "\n",
    "> Create a dataset of images that can be used to classify viseme and regress some face points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472e10a4-3741-44e1-a292-0ef51890613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from expoco.core import *\n",
    "from expoco.camera_capture import *\n",
    "import numpy as np\n",
    "import cv2, time, math, json, tempfile, shutil, zlib\n",
    "\n",
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b02d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageHelper:\n",
    "    def __init__(self):\n",
    "        self.face_detection = mp_face_detection.FaceDetection()\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "    def read_image(self, file_name):\n",
    "        assert Path(file_name).is_file(), f'Failed to read image. {file_name} not found'\n",
    "        return cv2.imread(str(file_name))\n",
    "    def write_image(self, file_name, image):\n",
    "        return cv2.imwrite(str(file_name), image)\n",
    "    def flip(self, image):\n",
    "        return cv2.flip(image, 1)\n",
    "    def get_face_bounding_box(self, image):\n",
    "        def normalized_x_to_pixel(value):\n",
    "            return math.floor(value * image.shape[1]) # width\n",
    "        def normalized_y_to_pixel(value):\n",
    "            return math.floor(value * image.shape[0]) # height\n",
    "        results = self.face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        if not results.detections:\n",
    "            return None\n",
    "        relative_bbox = results.detections[0].location_data.relative_bounding_box\n",
    "        xmin, width = [normalized_x_to_pixel(i) for i in [relative_bbox.xmin, relative_bbox.width]]\n",
    "        ymin, height = [normalized_y_to_pixel(i) for i in [relative_bbox.ymin, relative_bbox.height]]\n",
    "        return xmin, ymin, width, height\n",
    "    def resize_face_bounding_box(self, bbox, size=256):\n",
    "        xmin, ymin, width, height = bbox\n",
    "        xmin -= ((size - width) // 2)\n",
    "        ymin -= ((size - height) // 2)\n",
    "        return xmin, ymin, size, size\n",
    "    def face_crop(self, image, size=256):\n",
    "        bbox = self.get_face_bounding_box(image)\n",
    "        xmin, ymin, width, height = self.resize_face_bounding_box(bbox)\n",
    "        return image[ymin:ymin+height, xmin:xmin+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ec2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_no_test\n",
    "import win32api, win32con\n",
    "image_display_helper = ImageDisplayHelper(np.zeros((1,1)), 'expoco: camera capture')\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "try:\n",
    "    with ImageHelper() as image_helper:\n",
    "        while True:\n",
    "            retval, image = video_capture.read()\n",
    "            assert retval, 'failed to capture an image'\n",
    "            image = image_helper.flip(image)\n",
    "            bbox = image_helper.get_face_bounding_box(image)\n",
    "            image = image_helper.face_crop(image)\n",
    "            image = cv2.putText(image, f'{bbox}', (20,20), cv2.FONT_HERSHEY_COMPLEX, .5, 255)\n",
    "            image_display_helper.show(image)\n",
    "            if win32api.GetAsyncKeyState(win32con.VK_ESCAPE): \n",
    "                break\n",
    "            time.sleep(0.05)\n",
    "finally:\n",
    "    video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a476296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_zip(dataset_path):\n",
    "    default_compression=zlib.Z_DEFAULT_COMPRESSION\n",
    "    try:\n",
    "        zlib.Z_DEFAULT_COMPRESSION=0\n",
    "        shutil.make_archive(dataset_path/'data', 'zip', dataset_path/'images')\n",
    "    finally:\n",
    "        zlib.Z_DEFAULT_COMPRESSION=default_compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f594276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def viseme_image_dataset_from_capture_sessions(\n",
    "        input_path='data/capture_sessions', \n",
    "        glob_pattern='*', \n",
    "        change_y_from=None, change_y_to=None):\n",
    "    \"Create a viseme image dataset from capture session images\"\n",
    "    if change_y_from is not None: assert change_y_to is not None\n",
    "    input_path, dataset_id, image_helper = Path(input_path), now(), ImageHelper()\n",
    "    output_path = input_path.parent/f'viseme_image_dataset_{dataset_id}'\n",
    "    output_path.mkdir()\n",
    "    metadata = dict(input_path=path_to_str(input_path), output_path=path_to_str(output_path), \n",
    "                    glob_pattern=glob_pattern, session_metadata=[], start_date=now(),\n",
    "                    change_y_from=change_y_from, change_y_to=change_y_to,)\n",
    "    for session_path in sorted(input_path.glob(glob_pattern)):\n",
    "        with open(session_path/'metadata.json') as f:\n",
    "            session_metadata = json.load(f)\n",
    "        metadata['session_metadata'].append(session_metadata)\n",
    "        viseme_class = get_viseme_class(session_metadata)\n",
    "        if viseme_class == change_y_from:\n",
    "            viseme_class = change_y_to\n",
    "        for capture_count in range(1, session_metadata['count']+1):\n",
    "            image = image_helper.read_image(session_path/f'{capture_count}.png')\n",
    "            image = image_helper.face_crop(image)\n",
    "            image_file_path = output_path/f'images/{viseme_class}/{session_path.name}_{capture_count}.png'\n",
    "            image_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            image_helper.write_image(image_file_path, image)\n",
    "    _make_zip(output_path)\n",
    "    metadata['end_date'] = now()\n",
    "    with open(output_path/'metadata.json', 'w') as f: json.dump(metadata, f, indent=2)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0c2c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_no_test\n",
    "_image_dataset = viseme_image_dataset_from_capture_sessions(change_y_from='RANDOM_TALK', change_y_to='NO_EXPRESSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d661841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_stats(dataset_path, sample_fraction=0.1):\n",
    "    \"Color channel wise (BGR) mean and standard deviation\"\n",
    "    dataset_path = Path(dataset_path)\n",
    "    image_helper, images = ImageHelper(), []\n",
    "    for p in [p for p in (dataset_path/'images').iterdir() if p.is_dir()]:\n",
    "        file_paths = [f for f in p.iterdir()]\n",
    "        sample_size = round(len(file_paths) * sample_fraction)\n",
    "        print(p, 'sample_size', sample_size)\n",
    "        for f in np.random.choice(file_paths, sample_size, replace=False):\n",
    "            images.append(image_helper.read_image(f))\n",
    "    images = np.array(images) / 255.0\n",
    "    return images.mean(axis=(0,1,2)), images.std(axis=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f31c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\viseme_image_dataset_20211202_082908\\images\\AH sample_size 10\n",
      "data\\viseme_image_dataset_20211202_082908\\images\\EE sample_size 10\n",
      "data\\viseme_image_dataset_20211202_082908\\images\\NO_EXPRESSION sample_size 20\n",
      "data\\viseme_image_dataset_20211202_082908\\images\\OO sample_size 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.43687045, 0.40075572, 0.44365171]),\n",
       " array([0.22473524, 0.23717732, 0.2207213 ]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do_no_test\n",
    "calculate_stats(_image_dataset, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a25776a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_stats_to_metadata(dataset_path, stats):\n",
    "    with open(dataset_path/'metadata.json') as f: \n",
    "        metadata = json.load(f)\n",
    "    metadata['stats'] = dict(mean=np.round(stats[0], 4).tolist(), std=np.round(stats[1], 4).tolist())\n",
    "    with open(dataset_path/'metadata.json', 'w') as f: json.dump(metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e3ccafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\viseme_image_dataset_20211202_082908\\images\\AH sample_size 100\n",
      "data\\viseme_image_dataset_20211202_082908\\images\\EE sample_size 100\n",
      "data\\viseme_image_dataset_20211202_082908\\images\\NO_EXPRESSION sample_size 200\n",
      "data\\viseme_image_dataset_20211202_082908\\images\\OO sample_size 100\n"
     ]
    }
   ],
   "source": [
    "#do_no_test\n",
    "add_stats_to_metadata(_image_dataset, calculate_stats(_image_dataset, 1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a35b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01a_camera_capture.ipynb.\n",
      "Converted 10a_viseme_tabular_identify_landmarks.ipynb.\n",
      "Converted 10b_viseme_tabular_data.ipynb.\n",
      "Converted 10d_viseme_tabular_model.ipynb.\n",
      "Converted 10e_viseme_tabular_train_model.ipynb.\n",
      "Converted 10f_viseme_tabular_test_model.ipynb.\n",
      "Converted 11b_viseme_image_data.ipynb.\n",
      "Converted 11d_viseme_image_model.ipynb.\n",
      "Converted 11e_viseme_image_train_model.ipynb.\n",
      "Converted 11f_viseme_image_test_model.ipynb.\n",
      "Converted 20a_gui_capture_command.ipynb.\n",
      "Converted 20a_gui_main.ipynb.\n",
      "Converted 70_cli.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted project_lifecycle.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
