{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70959a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp viseme_image.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042ebe0",
   "metadata": {},
   "source": [
    "# Image model\n",
    "\n",
    "> Conv net, trained with fastai running in onnx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5196d33f-d07f-45da-af21-fdd22aad2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from expoco.viseme_image.data import *\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b6f01",
   "metadata": {},
   "source": [
    "# Prepare data for inference\n",
    "\n",
    "We need to replicate what fastai data loaders do ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc363eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_for_inference(image, crop=True):\n",
    "    \"Convert a cv2 style image to something that can be used as input to a CNN\"\n",
    "    if crop:\n",
    "        image = ImageHelper().face_crop(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = (image/255.)\n",
    "    image = image.astype(np.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500862e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_image = np.zeros((4, 5, 3), np.uint8)\n",
    "B, G, R = 255, 125, 0\n",
    "_image[:,] = B, G, R\n",
    "_image = prepare_for_inference(_image, False)\n",
    "assert _image.shape == (3, 4, 5)\n",
    "assert np.allclose(_image[0], R/255)\n",
    "assert np.allclose(_image[1], G/255)\n",
    "assert np.allclose(_image[2], B/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee9ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01a_camera_capture.ipynb.\n",
      "Converted 10a_viseme_tabular_identify_landmarks.ipynb.\n",
      "Converted 10b_viseme_tabular_data.ipynb.\n",
      "Converted 10d_viseme_tabular_model.ipynb.\n",
      "Converted 10e_viseme_tabular_train_model.ipynb.\n",
      "Converted 10f_viseme_tabular_test_model.ipynb.\n",
      "Converted 11b_viseme_image_data.ipynb.\n",
      "Converted 11d_viseme_image_model.ipynb.\n",
      "Converted 11f_viseme_image_test_model.ipynb.\n",
      "Converted 20a_gui_capture_command.ipynb.\n",
      "Converted 20a_gui_main.ipynb.\n",
      "Converted 70_cli.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted project_lifecycle.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
