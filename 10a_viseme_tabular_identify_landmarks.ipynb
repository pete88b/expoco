{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd5e2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp viseme_tabular.identify_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7113bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_do_not_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042ebe0",
   "metadata": {},
   "source": [
    "# Identify face mesh landmarks\n",
    "\n",
    "> Identify a subset of face mesh landmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c69596-fc0b-4d50-994d-7ce465baa145",
   "metadata": {},
   "source": [
    "How can we identify all the landmarks around the mouth?\n",
    "We could use [mesh_map.jpg](https://github.com/tensorflow/tfjs-models/blob/master/facemesh/mesh_map.jpg) and type out IDs of all the landmarks we're interested in but ... that'll take a while and will be hard to do without making any mistakes.\n",
    "\n",
    "How about we,\n",
    "- specify just 4 landmarks\n",
    "    - to specify the left, top, right and bottom of a bounding box\n",
    "- then find all other landmarks that are in this bounding box?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdb53caa-25a9-4cf5-9fe8-c2c16bbaf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from expoco.core import *\n",
    "import numpy as np\n",
    "import cv2, time, math\n",
    "import win32api, win32con\n",
    "\n",
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09cd528a-abcb-4d81-aec0-08118fbc638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "BoundingLandmarks = namedtuple('BoundingLandmarks', 'left, top, right, bottom')\n",
    "mouth_bounding_landmarks = BoundingLandmarks(57, 164, 287, 18)\n",
    "eye_bounding_landmarks = BoundingLandmarks(130, 223, 243, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44631b20-be66-4b96-b1aa-2a2856c2f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacePointHelper:\n",
    "    def __init__(self, image_height, image_width, bounding_landmarks):\n",
    "        self.image_height, self.image_width = image_height, image_width\n",
    "        self.bounding_landmarks = bounding_landmarks\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "        \n",
    "    def process(self, image):\n",
    "        self.results = self.face_mesh.process(image) # cv2.cvtColor(image, cv2.COLOR_BGR2RGB) already done\n",
    "        return self.results\n",
    "    \n",
    "    def get_bounding_box(self, pixel_coordinates=True):\n",
    "        fn = self._landmark_to_pixel_coordinates if pixel_coordinates else self._landmark_to_x_y\n",
    "        bls = BoundingLandmarks(*[fn(i) for i in self.bounding_landmarks])\n",
    "        return [bls.left[0], bls.top[1]], [bls.right[0], bls.bottom[1]]\n",
    "    \n",
    "    def get_bound_landmarks(self):\n",
    "        result = []\n",
    "        [left, top], [right, bottom] = self.get_bounding_box(False)\n",
    "        for i in range(468): # len(self.results.multi_face_landmarks[0])\n",
    "            landmark = self._landmark_to_x_y(i)\n",
    "            if left <= landmark[0] <= right and top <= landmark[1] <= bottom:\n",
    "                result.append(i)\n",
    "        return result\n",
    "                \n",
    "    def _landmark(self, i):\n",
    "        return self.results.multi_face_landmarks[0].landmark[i] # [0] is OK as we're running with max_num_faces=1\n",
    "        \n",
    "    def _is_valid_normalized_value(self, value):\n",
    "        return (value > 0 or math.isclose(0, value)) and (value < 1 or math.isclose(1, value))\n",
    "    \n",
    "    def _normalized_x_to_pixel(self, value):\n",
    "        return math.floor(value * self.image_width)\n",
    "    \n",
    "    def _normalized_y_to_pixel(self, value):\n",
    "        return math.floor(value * self.image_height)\n",
    "    \n",
    "    def _landmark_to_x_y(self, landmark):\n",
    "        if isinstance(landmark, int):\n",
    "            landmark = self._landmark(landmark)\n",
    "        if not (self._is_valid_normalized_value(landmark.x) and self._is_valid_normalized_value(landmark.y)):\n",
    "            print(f'WARNING: {landmark.x} or {landmark.y} is not a valid normalized value')\n",
    "        return landmark.x, landmark.y\n",
    "    \n",
    "    def _landmark_to_pixel_coordinates(self, landmark):\n",
    "        x, y = self._landmark_to_x_y(landmark)\n",
    "        return self._normalized_x_to_pixel(x), self._normalized_y_to_pixel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82d86e60-f7a8-4dba-b176-2b50d4e14d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image(face_point_helper, image):\n",
    "    if not face_point_helper.results.multi_face_landmarks:\n",
    "        return image\n",
    "    image = cv2.rectangle(image, *face_point_helper.get_bounding_box(), (130, 0, 130))\n",
    "    for i in face_point_helper.get_bound_landmarks():\n",
    "        point = face_point_helper._landmark_to_pixel_coordinates(i)\n",
    "        image = cv2.circle(image, point, radius=1, color=(100,0,0), thickness=-1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605e473-b2fc-40ce-9ba8-71030c69c453",
   "metadata": {},
   "source": [
    "run the following cell to see the bounding box and the landmarks it encloses.\n",
    "\n",
    "press `ESC` to print all landmarks enclosed by the bounding box and stop capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51754554-94c4-4cdd-9bdc-8f55d547496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3be08a6b3ae45c69a94391cb0ea6c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\x80\\x00\\x00\\x01\\xe0\\x08\\x02\\x00\\x00\\x00\\xba\\xb3Kâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 39, 40, 41, 42, 43, 57, 61, 62, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 106, 146, 164, 165, 167, 178, 179, 180, 181, 182, 183, 184, 185, 186, 191, 204, 267, 268, 269, 270, 271, 272, 273, 287, 291, 292, 302, 303, 304, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 335, 375, 391, 393, 402, 403, 404, 405, 406, 407, 408, 409, 410, 415, 424]\n"
     ]
    }
   ],
   "source": [
    "try: video_capture.release()\n",
    "except: pass\n",
    "video_capture = cv2.VideoCapture(0) \n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "for vk in [win32con.VK_ESCAPE, ord('D')]: win32api.GetAsyncKeyState(vk)\n",
    "retval, image = video_capture.read()\n",
    "face_point_helper = FacePointHelper(*image.shape[:2], mouth_bounding_landmarks)\n",
    "image_display_helper = ImageDisplayHelper(cv2.flip(image, 1), 'expoco: Dry Run')\n",
    "while True:\n",
    "    retval, image = video_capture.read()\n",
    "    image = cv2.flip(image, 1)\n",
    "    results = face_point_helper.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    image_display_helper.show(annotate_image(face_point_helper, image))\n",
    "    if win32api.GetAsyncKeyState(win32con.VK_ESCAPE): \n",
    "        print(face_point_helper.get_bound_landmarks())\n",
    "        video_capture.release()\n",
    "        break\n",
    "    time.sleep(.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ad6686-6d89-41c5-8d7b-abac5465bda4",
   "metadata": {},
   "source": [
    "output for `mouth_bounding_landmarks` should be;\n",
    "```\n",
    "[0, 11, 12, 13, 14, 15, 16, 17, 18, 37, 38, 39, 40, 41, 42, 43, 57, 61, 62, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 106, 146, 164, 165, 167, 178, 179, 180, 181, 182, 183, 184, 185, 186, 191, 204, 267, 268, 269, 270, 271, 272, 273, 287, 291, 292, 302, 303, 304, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 335, 375, 391, 393, 402, 403, 404, 405, 406, 407, 408, 409, 410, 415, 424]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
