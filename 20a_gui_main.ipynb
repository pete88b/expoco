{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f204a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp gui.main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0042ebe0",
   "metadata": {},
   "source": [
    "# ExPoCo GUI\n",
    "\n",
    "> The main expoco app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa901c",
   "metadata": {},
   "source": [
    "TODO: abstract out win32 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c30aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from expoco.core import *\n",
    "from expoco.viseme_image.data import *\n",
    "from expoco.viseme_image.model import *\n",
    "from expoco.gui.capture_command import *\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import cv2, time, math, json\n",
    "import win32api, win32con\n",
    "from PIL import Image\n",
    "\n",
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from collections import namedtuple\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba33cd1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2374f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "model_path = Path('data/viseme_image_dataset_20220202_131034/model_20220202_134036/resnet_3_256_256.onnx')\n",
    "viseme_classifier = VisemeClassifier(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a3890",
   "metadata": {},
   "source": [
    "# other ... todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a8b08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen_width, screen_height 1280 720\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "screen_width, screen_height = win32api.GetSystemMetrics(0), win32api.GetSystemMetrics(1)\n",
    "print('screen_width, screen_height', screen_width, screen_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e0dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class FacePoint:\n",
    "    x: int\n",
    "    y: int\n",
    "    def __call__(self): return self.x, self.y\n",
    "    def __repr__(self): return f'({self.x},{self.y})'\n",
    "    \n",
    "@dataclass\n",
    "class FacePoints:\n",
    "    tip_of_nose: FacePoint\n",
    "    up: FacePoint\n",
    "    down: FacePoint\n",
    "    left: FacePoint\n",
    "    right: FacePoint\n",
    "    face_point_ids = [1, 5, 2, 218, 438]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9d8c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FacePointHelper:\n",
    "    def __init__(self, image_width, image_height, screen_width, screen_height): # TODO: remove screen_width, screen_height\n",
    "        self.image_width, self.image_height = image_width, image_height\n",
    "        self.screen_width, self.screen_height = screen_width, screen_height\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "        \n",
    "    def process(self, image):\n",
    "        self.results = self.face_mesh.process(image) # cv2.cvtColor(image, cv2.COLOR_BGR2RGB) already done\n",
    "        return self.results\n",
    "        \n",
    "    def face_points(self, pixel_coordinates=True):\n",
    "        fn = self._landmark_to_pixel_coordinates if pixel_coordinates else self._landmark_to_x_y\n",
    "        return FacePoints(\n",
    "            *[FacePoint(*fn(i)) for i in FacePoints.face_point_ids])\n",
    "        \n",
    "    def face_orientation(self, calibration):\n",
    "        points = self.face_points(False)\n",
    "        l = points.tip_of_nose.x - points.left.x\n",
    "        r = points.right.x - points.tip_of_nose.x\n",
    "        u = points.tip_of_nose.y - points.up.y\n",
    "        d = points.down.y - points.tip_of_nose.y\n",
    "        pan = (l - r) - calibration[0] \n",
    "        tilt = (u - d) - calibration[1] # - 0.018 # TODO: calibrate\n",
    "        return pan, tilt, 0.0\n",
    "\n",
    "    def _landmark(self, i):\n",
    "        return self.results.multi_face_landmarks[0].landmark[i] # [0] is OK as we're running with max_num_faces=1\n",
    "        \n",
    "    def _is_valid_normalized_value(self, value):\n",
    "        return (value > 0 or math.isclose(0, value)) and (value < 1 or math.isclose(1, value))\n",
    "    \n",
    "    def _normalized_x_to_pixel(self, value):\n",
    "        return math.floor(value * self.image_width)\n",
    "    \n",
    "    def _normalized_y_to_pixel(self, value):\n",
    "        return math.floor(value * self.image_height)\n",
    "    \n",
    "    def _landmark_to_x_y(self, landmark):\n",
    "        if isinstance(landmark, int):\n",
    "            landmark = self._landmark(landmark)\n",
    "        if not (self._is_valid_normalized_value(landmark.x) and self._is_valid_normalized_value(landmark.y)):\n",
    "            print(f'WARNING: {landmark.x} or {landmark.y} is not a valid normalized value')\n",
    "        return landmark.x, landmark.y\n",
    "    \n",
    "    def _landmark_to_pixel_coordinates(self, landmark):\n",
    "        x, y = self._landmark_to_x_y(landmark)\n",
    "        return self._normalized_x_to_pixel(x), self._normalized_y_to_pixel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69840c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calibrate(face_point_helper):\n",
    "    win32api.SetCursorPos([screen_width//2, screen_height//2])\n",
    "    time.sleep(.5)\n",
    "    return face_point_helper.face_orientation([0.0,0.0,0.0])\n",
    "\n",
    "calibration = [0.0, 0.02087956666946411, 0.0]\n",
    "\n",
    "def reset_calibration(face_point_helper):\n",
    "    new_calibration = calibrate(face_point_helper)\n",
    "    print('old calibration', calibration)\n",
    "    print('new calibration', new_calibration)\n",
    "    for i in range(3):\n",
    "        calibration[i] = new_calibration[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14973358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def move(yaw, pitch):\n",
    "    pointer_x_px, pointer_y_px = list(win32api.GetCursorPos())\n",
    "    pointer_x_px -= screen_width//2\n",
    "    pointer_x_px /= 6.5e4 # 4.5e4 # was 5.5e4 # TODO: calibrate/pref\n",
    "    pointer_speed = 250 # TODO: user pref\n",
    "    x_move = math.floor(((yaw - pointer_x_px) * pointer_speed)**3) \n",
    "    pointer_y_px -= screen_height//2\n",
    "    pointer_y_px /= 6.5e4 # 4.5e4 # was 5.5e4 # TODO: calibrate\n",
    "    y_move = math.floor(((pitch - pointer_y_px) * pointer_speed)**3) \n",
    "    x, y = win32api.GetCursorPos()\n",
    "    win32api.SetCursorPos([x + x_move, y + y_move])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d174604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class StopExpocoException(Exception):\n",
    "    pass\n",
    "def stop_expoco():\n",
    "    raise StopExpocoException()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51b67b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "Command = namedtuple('Command', ['key', 'label', 'fn'])\n",
    "\n",
    "def build_commands(face_point_helper):\n",
    "    return [\n",
    "        Command('q', 'Quit', stop_expoco),\n",
    "        Command('l', 'Left click', lambda: pointer_left_click(*get_pointer_position())),\n",
    "        Command('r', 'Right click', lambda: pointer_right_click(*get_pointer_position())),\n",
    "        Command('semicolon', 'Enter / Return', lambda: win32api.keybd_event(win32con.VK_RETURN, 0)),\n",
    "        Command('e', 'End', lambda: win32api.keybd_event(win32con.VK_END, 0)),\n",
    "        Command('h', 'Home', lambda: win32api.keybd_event(win32con.VK_HOME, 0)),\n",
    "        Command('d', 'Delete', lambda: win32api.keybd_event(win32con.VK_DELETE, 0)),\n",
    "        Command('b', 'Backspace', lambda: win32api.keybd_event(win32con.VK_BACK, 0)),\n",
    "        Command('cc', 'Calibrate', partial(reset_calibration, face_point_helper)),\n",
    "        Command('as', 'Test seq', lambda: print('\"as\" sequence hit'))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05e98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SleepHelper:\n",
    "    def __init__(self, seconds=0.05):\n",
    "        self.seconds = seconds\n",
    "    def reset(self):\n",
    "        self.start = time.time()\n",
    "    def sleep(self):\n",
    "        diff = time.time() - self.start\n",
    "        seconds = self.seconds - diff\n",
    "        if seconds > 0:\n",
    "            time.sleep(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11070263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_main():\n",
    "    try:\n",
    "        video_capture = cv2.VideoCapture(0) \n",
    "        face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "        for vk in [win32con.VK_ESCAPE, ord('C')]: win32api.GetAsyncKeyState(vk)\n",
    "        retval, image = video_capture.read()\n",
    "        face_point_helper = FacePointHelper(*image.shape[:2], screen_width, screen_height)\n",
    "        sleep_helper = SleepHelper()\n",
    "        commands = build_commands(face_point_helper)\n",
    "        command_map = {c.key: c for c in commands}\n",
    "        while True:\n",
    "#             _start = time.time()\n",
    "            sleep_helper.reset()\n",
    "            retval, image = video_capture.read()\n",
    "            results = face_point_helper.process(cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB))\n",
    "            face_orientation = face_point_helper.face_orientation(calibration)\n",
    "            move(face_orientation[0], face_orientation[1])\n",
    "        #     if win32api.GetAsyncKeyState(ord('C')):\n",
    "        #         calibration = calibrate()\n",
    "        #         print('calibration', calibration)\n",
    "            # check each image for the \"enter command mode\" mouth shape\n",
    "#             class_ids = viseme_classifier.predict([image])\n",
    "#             if class_ids == ['OO']:\n",
    "#                 keys_pressed = capture_key_press([f\"{c.key}: {c.label}\" for c in commands], \n",
    "#                                                  not pointer_in_left_half_of_screen())\n",
    "#                 print('keys_pressed', keys_pressed)\n",
    "#                 run_command(command_map, keys_pressed)\n",
    "            # check pairs of images for the \"enter command mode\" mouth shape\n",
    "            viseme_classifier.queue_item(image)\n",
    "            if len(viseme_classifier.item_queue) > 1:\n",
    "                if viseme_classifier.predict() == ['OO','OO']:\n",
    "                    keys_pressed = capture_key_press([f\"{c.key}: {c.label}\" for c in commands], \n",
    "                                                     not pointer_in_left_half_of_screen())\n",
    "                    print('keys_pressed', keys_pressed)\n",
    "                    run_command(command_map, keys_pressed)\n",
    "    #         if win32api.GetAsyncKeyState(win32con.VK_ESCAPE): \n",
    "    #             break\n",
    "#             time.sleep(.05)\n",
    "            sleep_helper.sleep()\n",
    "#             print('actual time', time.time()-_start)\n",
    "    except StopExpocoException:\n",
    "        video_capture.release()\n",
    "    finally:\n",
    "        video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f464bf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys_pressed ['q']\n"
     ]
    }
   ],
   "source": [
    "run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee86d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01a_camera_capture.ipynb.\n",
      "Converted 10a_viseme_tabular_identify_landmarks.ipynb.\n",
      "Converted 10b_viseme_tabular_data.ipynb.\n",
      "Converted 10d_viseme_tabular_model.ipynb.\n",
      "Converted 10e_viseme_tabular_train_model.ipynb.\n",
      "Converted 10f_viseme_tabular_test_model.ipynb.\n",
      "Converted 11b_viseme_image_data.ipynb.\n",
      "Converted 11d_viseme_image_model.ipynb.\n",
      "Converted 11e_viseme_image_train_model.ipynb.\n",
      "Converted 11f_viseme_image_test_model.ipynb.\n",
      "Converted 20a_gui_capture_command.ipynb.\n",
      "Converted 20a_gui_main.ipynb.\n",
      "Converted 70_cli.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted project_lifecycle.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
