{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb4805f-d301-4afe-944b-e266e8a43cd8",
   "metadata": {},
   "source": [
    "# Create a dataset that can be used to classify a set of face mesh landmarks as a viseme\n",
    "\n",
    "expressions to capture\n",
    "- nothing\n",
    "- oo\n",
    "- ee\n",
    "- ar/ah\n",
    "- random talking - without exagerating expressions ...\n",
    "    - this should be ignored by pointer control\n",
    "    - MAYBE we should remove random talking examples that are classified as 0:nothing?\n",
    "\n",
    "while recording data\n",
    "- keep fingers on keyboard\n",
    "- exagerate expression - unless we're doing nothing/random talking\n",
    "- change lighing over different capture sessions\n",
    "- move around slowly\n",
    "    - up,down,left,right,corners etc\n",
    "- move forward and backward a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e10a4-3741-44e1-a292-0ef51890613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2, datetime, time, math, json, shutil\n",
    "import win32api, win32con\n",
    "\n",
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7d849-53bb-4816-aa88-029a0600bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _now(): \n",
    "    return datetime.datetime.utcnow().strftime('%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03285da-d513-4ac9-8737-831fa7ed32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _new_capture_metadata(stop_after, path, video_capture, expression_id, comments):\n",
    "    width, height = [int(video_capture.get(p)) for p in [cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT]]\n",
    "    assert width >= height\n",
    "    return dict(count=0, stop_after=stop_after, path=str(path.resolve()), expression_id=expression_id,\n",
    "                capture_width=width, capture_height=height, start_date=_now(), comments=comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce018e-e32d-48ec-a485-f8ea33525eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _setup_variables(expression_id):\n",
    "    expression_id = str(expression_id)\n",
    "    with open('../data/viseme-config.json') as f: config = json.load(f)\n",
    "    if expression_id not in config.get('expressions', {}):\n",
    "        raise Exception(f'{expression_id} is missing from expressions section of data/viseme-config.json')\n",
    "    expression_name = config['expressions'][expression_id]\n",
    "    path = Path(f'../data/viseme_capture_session_{_now()}_{expression_id}')\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    width, height = [int(video_capture.get(p)) for p in [cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT]]\n",
    "    assert width >= height\n",
    "    return expression_id, expression_name, path, video_capture, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c84e8-b523-4281-8ec5-d92e19faad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _setup_data():\n",
    "    data = dict(img_path=[])\n",
    "    for i in range(468):\n",
    "        for j in ['x','y','z']: \n",
    "            data[f'{i}{j}']=[]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6e706-299d-478c-acc2-55e1823f0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_image(image, image_widget, text):\n",
    "    image = cv2.putText(image, text, (20,40), cv2.FONT_HERSHEY_COMPLEX, 1, (200,200,200))\n",
    "    image_widget.value = cv2.imencode('.png', image)[1].tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21de584-c5aa-4dbf-9633-577b4068a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _capture_and_process(video_capture, face_mesh):\n",
    "    retval, image = video_capture.read() # TODO: check retval\n",
    "    image = cv2.flip(image, 1)\n",
    "    return image, face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d81ee-52ba-4760-a79d-71d058d0c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _countdown(video_capture, expression_name, image_widget, face_mesh):\n",
    "    for i in range(3,0,-1):\n",
    "        image, _ = _capture_and_process(video_capture, face_mesh)\n",
    "        _update_image(image, image_widget, f'Capture: {expression_name} in {i}s')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9020a3c-55b4-4eba-b40d-a0a922b22321",
   "metadata": {},
   "source": [
    "when we `_save_results`\n",
    "- we want to save some images so we can check why things are being misclassified etc\n",
    "- so that we don't create too much data, we can\n",
    "    - save one in 10 images at high quality or\n",
    "    - save all images at low quality\n",
    "- if we wanted to be able to re-calculate landmarks (i.e. if mediapipe changed) we might need to save all images at high quality\n",
    "    - TODO: see if we get the same landmark data from low res images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdff965-aa8b-442f-8cdb-c9e2e4c9af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_results(path, results, data, image, capture_count):\n",
    "    # save all landmarks calculated\n",
    "    for landmark_id in range(468):\n",
    "        landmark = results.multi_face_landmarks[0].landmark[landmark_id]\n",
    "        for coord in ['x','y','z']: \n",
    "            data[f'{landmark_id}{coord}'].append(getattr(landmark, coord))\n",
    "    # save one in 10 images\n",
    "#     if capture_count % 10 == 0: \n",
    "#         img_name = f'{_now()}_{capture_count}.png'\n",
    "#         assert cv2.imwrite(f'{path}/{img_name}', image)\n",
    "#         data['img_path'].append(img_name)\n",
    "#     else:\n",
    "#         data['img_path'].append('')\n",
    "    # but we can save all as low res - using less space than a single png (even at max compression)\n",
    "    img_name = f'{_now()}_{capture_count}.jpeg'\n",
    "    assert cv2.imwrite(f'{path}/{img_name}', image, [cv2.IMWRITE_JPEG_QUALITY, 50])\n",
    "    data['img_path'].append(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444e5fb-0c2b-4855-abb7-59710ed01250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dry_run():\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    retval, image = video_capture.read()\n",
    "    image = cv2.flip(image, 1)\n",
    "    image_widget = widgets.Image(value=cv2.imencode('.png', image)[1].tobytes())\n",
    "    display(image_widget)\n",
    "    while True:\n",
    "        if win32api.GetAsyncKeyState(win32con.VK_ESCAPE): \n",
    "            video_capture.release()\n",
    "            break\n",
    "        retval, image = video_capture.read()\n",
    "        image = cv2.flip(image, 1)\n",
    "        image_widget.value = cv2.imencode('.png', image)[1].tobytes()\n",
    "        time.sleep(.05)\n",
    "    image_widget.close()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4370f94-dd7f-4c6a-94cc-7fa3e031265f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\x80\\x00\\x00\\x01\\xe0\\x08\\x02\\x00\\x00\\x00\\xba\\xb3Kâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = dry_run() # press ESC to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172eb899-a4c6-4856-8d62-d85836ceb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def capture_session(expression_id, stop_after, comments):\n",
    "    \"Run a video capture session\"\n",
    "    expression_id, expression_name, path, video_capture, width, height = _setup_variables(expression_id)\n",
    "    face_mesh = mp_face_mesh.FaceMesh(max_num_faces=1)\n",
    "    data = _setup_data()\n",
    "    image, _ = _capture_and_process(video_capture, face_mesh)\n",
    "    image_widget = widgets.Image(value=cv2.imencode('.png', image)[1].tobytes())\n",
    "    display(image_widget)\n",
    "    try:\n",
    "        _countdown(video_capture, expression_name, image_widget, face_mesh)\n",
    "        capture_metadata = _new_capture_metadata(stop_after, path, video_capture, expression_id, comments)\n",
    "        for capture_count in range(1, stop_after+1):\n",
    "            image, results = _capture_and_process(video_capture, face_mesh)\n",
    "            _update_image(image, image_widget, f'{expression_name} {capture_count}')\n",
    "            _save_results(path, results, data, image, capture_count)\n",
    "            time.sleep(.05)\n",
    "        capture_metadata['count'] = capture_count\n",
    "        capture_metadata['end_data'] = _now()\n",
    "        with open(path/'capture_metadata.json', 'w') as f: json.dump(capture_metadata, f, indent=2)\n",
    "        pd.DataFrame(data).to_csv(path/'data.csv', index=False)\n",
    "    finally:\n",
    "        video_capture.release()\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade25fd-2789-459d-82b2-af0dea8e4a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36aecdb6783475ca1070f4e0ef6eb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02\\x80\\x00\\x00\\x01\\xe0\\x08\\x02\\x00\\x00\\x00\\xba\\xb3Kâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = capture_session(3, 500, 'nearly clean shaven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816ad06-5c7a-4aab-9d02-83a8acf3cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(path/'data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c555da-2185-479a-af36-d5d886257154",
   "metadata": {},
   "source": [
    "# clear out an old viseme data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ed362-64ae-4020-895a-3e77d4d61e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = Path('../data')\n",
    "# for path in data_path.glob('viseme_capture_session*'):\n",
    "#     print('removing', path)\n",
    "#     shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d0c22-4ef2-4984-a53f-2d79da9a5856",
   "metadata": {},
   "source": [
    "# create a single csv of all data.csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb940d7e-36bf-4530-a738-c87d9777f3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\data\\viseme_capture_session_20211013101459_0 0\n",
      "..\\data\\viseme_capture_session_20211013101550_0 0\n",
      "..\\data\\viseme_capture_session_20211013101745_1 1\n",
      "..\\data\\viseme_capture_session_20211013101930_1 1\n",
      "..\\data\\viseme_capture_session_20211013102156_2 2\n",
      "..\\data\\viseme_capture_session_20211013102325_2 2\n",
      "..\\data\\viseme_capture_session_20211013102443_3 3\n",
      "..\\data\\viseme_capture_session_20211013102614_3 3\n",
      "..\\data\\viseme_capture_session_20211014132309_4 4\n",
      "..\\data\\viseme_capture_session_20211014132409_4 4\n",
      "..\\data\\viseme_capture_session_20211014132511_0 0\n",
      "..\\data\\viseme_capture_session_20211014132600_0 0\n",
      "..\\data\\viseme_capture_session_20211014132750_1 1\n",
      "..\\data\\viseme_capture_session_20211014132840_1 1\n",
      "..\\data\\viseme_capture_session_20211014141645_2 2\n",
      "..\\data\\viseme_capture_session_20211014141805_2 2\n",
      "..\\data\\viseme_capture_session_20211014141927_3 3\n",
      "..\\data\\viseme_capture_session_20211014142018_3 3\n",
      "..\\data\\viseme_capture_session_20211014142904_4 4\n",
      "..\\data\\viseme_capture_session_20211014142958_4 4\n",
      "..\\data\\viseme_capture_session_20211018120155_0 0\n",
      "..\\data\\viseme_capture_session_20211018120342_1 1\n",
      "..\\data\\viseme_capture_session_20211018120454_2 2\n",
      "..\\data\\viseme_capture_session_20211018120644_3 3\n",
      "file_name ..\\data\\data_20211018120917.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('../data')\n",
    "df = pd.DataFrame()\n",
    "for path in data_path.glob('viseme_capture_session*'):\n",
    "    print(path, str(path)[-1])\n",
    "    _df = pd.read_csv(path/'data.csv')\n",
    "    _df['expression_id']=int(str(path)[-1])\n",
    "    df = pd.concat([df,_df])\n",
    "file_name=data_path/f'data_{_now()}.csv'\n",
    "df.to_csv(file_name, index=False)\n",
    "print('file_name',file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664b647-e2c0-4c98-89d6-578849b2b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
